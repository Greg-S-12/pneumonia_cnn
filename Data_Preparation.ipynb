{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Organising Data](#first-bullet)\n",
    "* [Formatting the Data](#second-bullet)\n",
    "* [Class Imbalance](#third-bullet)\n",
    "\n",
    "# Preparing the Data\n",
    "This notebook will allow the user to read in the data from Kaggle and prepare it for training and testing. With a few minor changes to code, the user can change: the train/test/validation split sizes, the classes to be predicted (e.g. bacterial/viral/healthy or pneumonia/healthy), the shape of the images for analysis and more.\n",
    "\n",
    "## [Organising the Data](#first-bullet)\n",
    "\n",
    "### Creating Three Classes from Two\n",
    "This dataset is from kaggle and can be found here: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "<br> The original dataset has already split the data into train, test and validation sets before splitting them into cases of Pneumonia and Normal (healthy) lungs. In reality Pneumonia can be caused by a bacterial infection or a viral one.\n",
    "<br> For this project, I wish to see if the model can solve a multi-class problem as well as a binary one. Using Convolutional Neural Networks to classify either cases of Pneumonia vs. healthy lungs, before further breaking the pneumonia class down into viral and bacterial. To do so we must create our own classes which requires splitting the images up differently to how this dataset is provided - such that there are 3 different classes: Normal (healthy), Bacterial and Viral.\n",
    "\n",
    "###  Train, Test and Validation Split and Class Imbalance\n",
    "I will further create a train, test and validation split based around these classes. The test set will remained untouched and unseen until the final model is tested  in the third notebook. Validation is used during training to aid the user in avoiding overfitting of the training data.\n",
    "<br> We will also see there is a class imbalance in the dataset which will bias our algorithm in its classifcation. This also makes the accuracy metric (used to evaluate how \"good\" the model is at classifying images) misleading and not a valid representation of the true model performance.\n",
    "<br>\n",
    "## [Formatting the Data](#second-bullet)\n",
    "\n",
    "### Resizing Images\n",
    "As the dataset is a few thousand images all with large resolution we will have to resize these such that the training of our model doesnt take too long. This will be something to consider in optimization of the model too - if transfer . learning is used (such as from VGG16) then the image will have to be of a certain shape and color scheme (grayscale or RGB).\n",
    "\n",
    "### Rescaling\n",
    "This is also known as normalization. Each pixel in an image has a value of 0-255 depending on its contrast. Each image will contain a varying number of each value, meaning a different range of values -  a larger range will contribute more to the loss whereas a smaller range has a smaller contribution. When this is put into our model the network the weights update accordingly. We want each image treated equally so by scaling, we put all the values in the same range 0-1.\n",
    "\n",
    "## [Class Imbalance](#third-bullet)\n",
    "### Image Generation\n",
    "To account for the inital class imbalance we can create new images using the data in our posession. We can do this by flipping, stretching and rotating the images - as long as the augmentation matches what could happen with an actual x-ray image.\n",
    "<br> It is important to note that in this step we will NOT be generating new data IN ADDITION to our training data, but rather we REPLACE the training data in each batch with the augmented images. This is known as \"on-the-fly\" image generation and is the most commonplace method.\n",
    "\n",
    "### Class Weighting\n",
    "An alternative method to data generation is weighting the classes. This will bias the learning so that the undersampled classes are more heavily weighted and therefore all classes are treated equally. This restores the validity of the accuracy metric for model evaluation.\n",
    "<br> While this method has the advantages of being quicker to execute and simpler so less can go wrong, we lose out on training the model on a larger dataset so are more prone to overfitting or worse model performance (on the validation/test sets).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising Data <a class=\"anchor\" id=\"first-bullet\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Set Seed for Reproducibilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import data_prep as dp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment seed for Python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=101\n",
    "\n",
    "# Set seed for Numpy, TensorFlow and for image augmentation sequence\n",
    "np.random.seed(seed)\n",
    "# aug.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the Data Properly\n",
    "We will create a new directory for all images and store them within train, test and validation folders with each class as a subfolder.\n",
    "\n",
    "A lot can go wrong during the whole process of altering the files, training and testing the models so I strongly advise using **github** and committing/pushing often to save your changes. Furthermore training these networks takes a lot of processing power so using **AWS or Google Cloud platform will greatly speed this process up** and you can get free credits when you sign up!\n",
    "\n",
    "As a result of the above (using git) and due to the fact that these **files are very large** it is a good idea to store these images in a new folder and put it in a **.gitignore** file so they are not committed/pushed as this is very likely to be **above the size limit** (especially if you plan on pushing your saved weights (h5) folders!!!). \n",
    "\n",
    "(Alternatively you could try using Git Large File Storage (Git LFS) which acts as an 'pointer' to where the files are located without actually uploading them. However I have experienced issues with this with Git and when combining this with Google Cloud and may corrupt your git branch so I'd reccommend the .gitignore method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new directory for our images\n",
    "os.mkdir('Docs/all_xrays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the folders for each class in each split\n",
    "location = 'Docs/all_xrays'\n",
    "splits = ['{}/train'.format(location),'{}/test'.format(location),'{}/val'.format(location)]\n",
    "list_of_classes = ['normal','virus','bacteria']\n",
    "dp.make_classes(splits, list_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of filenames\n",
    "location = '../'\n",
    "normal = dp.find_files(location, \"0001\")\n",
    "virus = dp.find_files(location, \"virus\")\n",
    "bacteria = dp.find_files(location, \"bacteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1582, 1493, 2780)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal),len(virus),len(bacteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform our Train, Test, Validation split and move files to respective folders\n",
    "\n",
    "split_percentages = [0.79, 0.2, 0.01] # Train, Test, Validation\n",
    "files_dict = {'normal':normal,'virus':virus,'bacteria':bacteria}\n",
    "groups = list_of_classes\n",
    "directory = '../'\n",
    "destination_folder = 'Docs/all_xrays'\n",
    "\n",
    "dp.move_files_to_groups_by_split(split_percentages, files_dict, groups, directory, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Class Imbalance\n",
    "We will label each image the corresponding class, create a dataframe and visualize the imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Data <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "### Importing Libraries to be sed in Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import cv2\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2196\n",
       "0    1249\n",
       "1    1179\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and label each image according to class\n",
    "filer=dp.Files()\n",
    "\n",
    "normal = filer.find_files('Docs/all_xrays/train/normal', \"0001\").files\n",
    "virus = filer.find_files('Docs/all_xrays/train/virus', \"virus\").files\n",
    "bacteria = filer.find_files('Docs/all_xrays/train/bacteria', \"bacteria\").files\n",
    "\n",
    "files_dict = {'normal':normal,'virus':virus,'bacteria':bacteria}\n",
    "training_dataset = []\n",
    "iteration=-1\n",
    "\n",
    "for files in files_dict:\n",
    "    iteration+=1\n",
    "    for file in files_dict[files]:\n",
    "        training_dataset.append((file,iteration))\n",
    "        \n",
    "df_train = pd.DataFrame(training_dataset, columns=(\"file\",\"class\"))\n",
    "df_train['class'] = df_train['class'].astype(dtype='category')\n",
    "\n",
    "df_train['class'].value_counts() # 0 = Bacterial ; 1 = Viral ; 2 = Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    27\n",
       "0    15\n",
       "1    14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and label each image according to class\n",
    "filer=dp.Files()\n",
    "\n",
    "normal = filer.find_files('Docs/all_xrays/val/normal', \"0001\").files\n",
    "virus = filer.find_files('Docs/all_xrays/val/virus', \"virus\").files\n",
    "bacteria = filer.find_files('Docs/all_xrays/val/bacteria', \"bacteria\").files\n",
    "\n",
    "files_dict = {'normal':normal,'virus':virus,'bacteria':bacteria}\n",
    "validation_dataset = []\n",
    "iteration=-1\n",
    "\n",
    "for files in files_dict:\n",
    "    iteration+=1\n",
    "    for file in files_dict[files]:\n",
    "        validation_dataset.append((file,iteration))\n",
    "        \n",
    "df_val = pd.DataFrame(validation_dataset, columns=(\"file\",\"class\"))\n",
    "df_val['class'] = df_val['class'].astype(dtype='category')\n",
    "\n",
    "df_val['class'].value_counts() # 2 = Bacterial ; 1 = Viral ; 0 = Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing, Normalizing and Converting to Grayscale\n",
    "Below, I identify the files for each class in either the training or validation samples. I then resize to lower resolution to reduce memory, rescale to normalize the pixels in each image and convert to grayscale as these are x-rayds.\n",
    "<br> To confirm the images are actually in grayscale you can look at the matrix of the pixels in the ikage. You can see for each colour (BGR, as is read by OpenCV) that the values are the same, meaning we can safely convert to grayscale, saving memory and simplifying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4ff5e601041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the list of all the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnormal_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_xrays/val/normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mvirus_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_xrays/val/virus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"virus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbacteria_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_xrays/val/bacteria'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bacteria\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dp' is not defined"
     ]
    }
   ],
   "source": [
    "val_directory = 'Docs/all_xrays/val/'\n",
    "filer=dp.Files()\n",
    "\n",
    "normal_cases_dir = '{}normal'.format(val_directory)\n",
    "bacteria_cases_dir = '{}bacteria'.format(val_directory)\n",
    "virus_cases_dir = '{}virus'.format(val_directory)\n",
    "\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = filer.find_files('Docs/all_xrays/val/normal', \"0001\").files\n",
    "virus_cases = filer.find_files('Docs/all_xrays/val/virus', \"virus\").files\n",
    "bacteria_cases = filer.find_files('Docs/all_xrays/val/bacteria', \"bacteria\").files\n",
    "\n",
    "\n",
    "# List that are going to contain validation image data and the corresponding labels\n",
    "val_files = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "\n",
    "# Normal \n",
    "iteration=0\n",
    "for img in normal_cases:\n",
    "    val_files.append(img)\n",
    "    img = cv2.imread(os.path.join(normal_cases_dir,img)) # Locate our image\n",
    "    img = cv2.resize(img, (224,224))                     # Resize to reduce size of file (to speed up training later). Keeping our ratio of vertical:horizontal widths.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)          # Convert to grayscale as some files stored as rgb, despite being taken in grayscale. Reduces size as above.\n",
    "    img = img.astype(np.float32)/255.                    # Convert pixels to float and rescale to normalize data (allows traing to converge) and also treats all images equally\n",
    "                                                         # imgaug => forbidden dtypes: (uint32, uint64, uint128, uint256, int32, int64, int128, int256, float64, float96, float128, float256).\n",
    "    label = to_categorical(0, num_classes=3)             # Labels class, number of classes - one-hot encoding\n",
    "    val_data.append(img)\n",
    "    val_labels.append(label)\n",
    "\n",
    "# Virus \n",
    "for img in virus_cases:\n",
    "    val_files.append(img)\n",
    "    img = cv2.imread(os.path.join(virus_cases_dir,img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=3)\n",
    "    val_data.append(img)\n",
    "    val_labels.append(label)\n",
    "    \n",
    "# Bacteria \n",
    "for img in bacteria_cases:\n",
    "    val_files.append(img)\n",
    "    img = cv2.imread(os.path.join(bacteria_cases_dir,img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(2, num_classes=3)\n",
    "    val_data.append(img)\n",
    "    val_labels.append(label) \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "# Convert the list into numpy arrays\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels).astype(int)\n",
    "\n",
    "print(\"Total number of validation examples: \", val_data.shape)\n",
    "print(\"Total number of labels:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance <a class=\"anchor\" id=\"third-bullet\"></a>\n",
    "### Creating the Sequence\n",
    "Below we will create the sequence to augment our data \"on-the-fly\" to be used in the training of our model.\n",
    "<br> OneOf allows us to choose one of the below augmentations and apply it to each image in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3755b6dfaee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m seq = iaa.OneOf([iaa.Fliplr(0.5),     # Horizontally flip 50% of the images\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0miaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Size of rotation range in degrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0miaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Makes pixels darker or brighter, random amount between 1.2 and 1.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0miaa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      ]) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'iaa' is not defined"
     ]
    }
   ],
   "source": [
    "seq = iaa.OneOf([iaa.Fliplr(0.5),     # Horizontally flip 50% of the images\n",
    "                    iaa.Affine(rotate=(-20,20)), # Size of rotation range in degrees\n",
    "                    iaa.Multiply((1.2, 1.5)), # Makes pixels darker or brighter, random amount between 1.2 and 1.5\n",
    "                    iaa.Crop(percent=(0, 0.05))\n",
    "                     ]) \n",
    "\n",
    "# There is more one can do here - contrast, rotation etc. - but this is enough to demonstrate its purpose.\n",
    "# It is better to start simple and slowly build up both the data generator and model to avoid overcomplicating things.\n",
    "# This allows the user to more easily identify what changes produce which results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Data Generator \n",
    "The data generator will be used for training of the model. This will allow us to perform augmentations of the original training data in batches and train upon each one of these.  This is particularly important as it will be used to account for the class imbalance by generating more of the undersampled class for each batch.\n",
    "\n",
    "Here is one for the multi-class problem, it has been adapted from one created by the user NAIN in this kernel: https://www.kaggle.com/aakashnain/beating-everything-with-depthwise-convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, batch_size, directory):\n",
    "    \n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, 224,224,3),dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, 3),dtype=np.float32)\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Initialize a counter\n",
    "    i = 0\n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        # Get the next batch \n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['file']\n",
    "            label = data.iloc[idx]['class']            \n",
    "            \n",
    "            # read the image and resize\n",
    "            if \"0001\" in img_name:\n",
    "                img = cv2.imread(str(os.path.join(\"{}normal\".format(directory),str(img_name))))\n",
    "                img = cv2.resize(img, (224,224)) # Setting the size of all the images as 224x224 - standard input size for VGG-16\n",
    "            \n",
    "            elif \"virus\" in img_name:\n",
    "                img = cv2.imread(str(os.path.join(\"{}virus\".format(directory),str(img_name))))\n",
    "                img = cv2.resize(img, (224,224))\n",
    "                                 \n",
    "            else:\n",
    "                img = cv2.imread(str(os.path.join(\"{}bacteria\".format(directory),str(img_name))))\n",
    "                img = cv2.resize(img, (224,224))\n",
    "            \n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=3)\n",
    "            \n",
    "            if img.shape[2]==1:       \n",
    "                img = np.dstack([img, img, img])  # If grayscale then converts to rgb.\n",
    "            \n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "            \n",
    "            batch_images[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "            \n",
    "            # generating more samples of the undersampled class\n",
    "            if label==0 and count < batch_size-2:\n",
    "                aug_img_n = seq.augment_image(img)\n",
    "                aug_img_n = cv2.cvtColor(aug_img_n, cv2.COLOR_BGR2RGB)\n",
    "                aug_img_n = aug_img_n.astype(np.float32)/255.\n",
    "\n",
    "                batch_images[count+1] = aug_img_n\n",
    "                batch_labels[count+1] = encoded_label\n",
    "                \n",
    "                count +=1\n",
    "\n",
    "            elif label==1 and count < batch_size-2:\n",
    "                aug_img_v = seq.augment_image(img)\n",
    "                aug_img_v = cv2.cvtColor(aug_img_v, cv2.COLOR_BGR2RGB)\n",
    "                aug_img_v = aug_img_v.astype(np.float32)/255.\n",
    "                \n",
    "                batch_images[count+2] = aug_img_v\n",
    "                batch_labels[count+2] = encoded_label\n",
    "\n",
    "                count +=1\n",
    "            \n",
    "            else:\n",
    "                count+=1\n",
    "            \n",
    "            if count==batch_size-1:\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "        yield batch_images, batch_labels\n",
    "            \n",
    "        if i>=steps:\n",
    "            i=0    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting the classes\n",
    "If the user wishes to avoid using data generation - class weightings can be used. The weightings are input during  training of the model. Below, the weightings are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1249, 2196, 1179)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find files for each class in training dataset\n",
    "filer=dp.Files()\n",
    "\n",
    "# Create list of files\n",
    "normal = filer.find_files('Docs/all_xrays/train/normal', \"0001\").files\n",
    "virus = filer.find_files('Docs/all_xrays/train/virus', \"virus\").files\n",
    "bacteria = filer.find_files('Docs/all_xrays/train/bacteria', \"bacteria\").files\n",
    "\n",
    "# Sample populations\n",
    "len(normal),len(bacteria),len(virus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.86, 1.76, 2.7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine weightings\n",
    "\n",
    "# 3 Class problem\n",
    "virus_weighting = len(bacteria)/len(virus)\n",
    "normal_weighting = len(bacteria)/len(normal)\n",
    "\n",
    "# Binary Problem\n",
    "normal_weighting_binary = (len(virus)+len(bacteria))/len(normal)\n",
    "\n",
    "# Print weights (to 2dp)\n",
    "round(virus_weighting,2), round(normal_weighting,2), round(normal_weighting_binary,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
