{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import data_prep as dp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment seed for Python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=101\n",
    "\n",
    "# Set seed for Numpy\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3375\n",
       "0    1249\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and label each image according to class\n",
    "filer=dp.Files()\n",
    "\n",
    "normal = filer.find_files('all_xrays/train/normal', \"0001\").files\n",
    "virus = filer.find_files('all_xrays/train/virus', \"virus\").files\n",
    "bacteria = filer.find_files('all_xrays/train/bacteria', \"bacteria\").files\n",
    "\n",
    "pneumonia = (virus+bacteria)\n",
    "\n",
    "files_dict = {'normal':normal,'pneumonia':pneumonia}\n",
    "training_dataset = []\n",
    "iteration=-1\n",
    "\n",
    "for files in files_dict:\n",
    "    iteration+=1\n",
    "    for file in files_dict[files]:\n",
    "        training_dataset.append((file,iteration))\n",
    "        \n",
    "\n",
    "df_train = pd.DataFrame(training_dataset, columns=(\"file\",\"class\"))\n",
    "df_train['class'] = df_train['class'].astype(dtype='category')\n",
    "\n",
    "df_train['class'].value_counts() # 0 = Bacterial ; 1 = Viral ; 2 = Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    27\n",
       "0    15\n",
       "1    14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and label each image according to class\n",
    "\n",
    "normal = filer.find_files('all_xrays/val/normal', \"0001\").files\n",
    "virus = filer.find_files('all_xrays/val/virus', \"virus\").files\n",
    "bacteria = filer.find_files('all_xrays/val/bacteria', \"bacteria\").files\n",
    "\n",
    "files_dict = {'normal':normal,'virus':virus,'bacteria':bacteria}\n",
    "validation_dataset = []\n",
    "iteration=-1\n",
    "\n",
    "# Create list of file and corresponding label\n",
    "for files in files_dict:\n",
    "    iteration+=1\n",
    "    for file in files_dict[files]:\n",
    "        validation_dataset.append((file,iteration))\n",
    "\n",
    "# Convert list to dataframe        \n",
    "df_val = pd.DataFrame(validation_dataset, columns=(\"file\",\"class\"))\n",
    "df_val['class'] = df_val['class'].astype(dtype='category')\n",
    "\n",
    "# Check the number of files in each class \n",
    "df_val['class'].value_counts() # 2 = Bacterial ; 1 = Viral ; 0 = Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'file_directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b5cd5c0efe2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubfolders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of validation examples: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pneumonia_cnn/data_prep.py\u001b[0m in \u001b[0;36mimage_data_and_labels\u001b[0;34m(imagetype, directory, subfolders, class_labels)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0msubfolder_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimagetype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# List of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pneumonia_cnn/data_prep.py\u001b[0m in \u001b[0;36mfind_files\u001b[0;34m(self, file_directory, condition)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_directory\u001b[0m     \u001b[0;31m# Keep track of the files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# Empty list so we manage this batch of files and can chain methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'file_directory'"
     ]
    }
   ],
   "source": [
    "directory='all_xrays/val/'\n",
    "subfolders=['normal','virus','bacteria']\n",
    "class_labels=[0,1,1]\n",
    "\n",
    "val_data, val_labels = dp.image_data_and_labels('.jpeg',directory,subfolders,class_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", val_data.shape)\n",
    "print(\"Total number of labels:\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of validation examples:  (4625, 224, 224, 3)\n",
      "Total number of labels: (4625, 2)\n"
     ]
    }
   ],
   "source": [
    "directory='all_xrays/train/'\n",
    "subfolders=['normal','virus','bacteria']\n",
    "class_labels=[0,1,1]\n",
    "\n",
    "train_data, train_labels = dp.image_data_and_labels('.jpeg',directory,subfolders,class_labels)\n",
    "\n",
    "print(\"Total number of validation examples: \", train_data.shape)\n",
    "print(\"Total number of labels:\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.seed(seed)\n",
    "seq = iaa.OneOf(random_state=seed,\n",
    "                children=[\n",
    "                    iaa.Crop(px=(0, 4)),\n",
    "                    #iaa.Fliplr(),     # Horizontally flip 50% of the images\n",
    "                    #iaa.Affine(\n",
    "                   # rotate=(-5, 5)),         # Size of rotation range in degrees\n",
    "                    iaa.Multiply((1, 1.2))]) # Makes pixels darker or brighter, random amount between 1.2 and 1.5\n",
    "                    #iaa.contrast.LinearContrast((0.75, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Model\n",
    "In this model I will take advantage of depthwise convolution and batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import sigmoid\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "\n",
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SeparableConv2D, BatchNormalization, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vggmodel = VGG16()\n",
    "# vggmodel.summary()\n",
    "# vggmodel.save('vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_prep as dp\n",
    "\n",
    "\n",
    "directory='all_xrays/train'\n",
    "destination='all_xrays/val'\n",
    "subs={0:'normal',1:'virus',2:'bacteria'}\n",
    "\n",
    "files=[]\n",
    "\n",
    "\n",
    "# for i in subs:\n",
    "#     dp.move_files(directory,files,destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "size=(224,224)\n",
    "\n",
    "model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[0])\n",
    "model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[1])\n",
    "model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[2])\n",
    "model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[3])\n",
    "\n",
    "model_2.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv1_1'))\n",
    "model_2.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv1_2'))\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool1'))\n",
    "\n",
    "model_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv2_1'))\n",
    "model_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv2_2'))\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool2'))\n",
    "\n",
    "model_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv3_1'))\n",
    "model_2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv3_2'))\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool3'))\n",
    "\n",
    "model_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv4_1'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv4_2'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool4'))\n",
    "\n",
    "model_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv5_1'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv5_2'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool5'))\n",
    "\n",
    "model_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv6_1'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"swish\", name='Conv6_2'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool6'))\n",
    "\n",
    "model_2.add(Flatten(name=\"Flatten\"))\n",
    "model_2.add(Dense(units=1024,activation=\"swish\", name='Dense1'))\n",
    "model_2.add(Dense(units=512,activation=\"swish\", name='Dense2'))\n",
    "model_2.add(Dense(units=2, activation=\"softmax\", name='Result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# model_2 = Sequential()\n",
    "\n",
    "# size=(224,224)\n",
    "\n",
    "# model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[0])\n",
    "# model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[1])\n",
    "# model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[2])\n",
    "# model_2.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[3])\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv1_1'))\n",
    "# model_2.add(SeparableConv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv1_2'))\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool1'))\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv2_1'))\n",
    "# model_2.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv2_2'))\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool2'))\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv3_1'))\n",
    "# model_2.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv3_2'))\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool3'))\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv4_1'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv4_2'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool4'))\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv5_1'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv5_2'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool5'))\n",
    "\n",
    "# model_2.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv6_1'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv6_2'))\n",
    "# model_2.add(BatchNormalization())\n",
    "# model_2.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool6'))\n",
    "\n",
    "# model_2.add(Flatten(name=\"Flatten\"))\n",
    "# model_2.add(Dropout(0.2))\n",
    "# model_2.add(Dense(units=1024,activation=\"relu\", name='Dense1'))\n",
    "# model_2.add(Dense(units=512,activation=\"relu\", name='Dense2'))\n",
    "# model_2.add(Dense(units=2, activation=\"softmax\", name='Result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x7f92e7e8af98>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f92e80f3940>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f92e81d3128>\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "Pool1 (MaxPooling2D)         (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (Conv2D)             (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "Conv2_2 (Conv2D)             (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "Pool2 (MaxPooling2D)         (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (Conv2D)             (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "Conv3_2 (Conv2D)             (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "Pool3 (MaxPooling2D)         (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (Conv2D)             (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (Conv2D)             (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Pool4 (MaxPooling2D)         (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv5_1 (Conv2D)             (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "Conv5_2 (Conv2D)             (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "Pool5 (MaxPooling2D)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv6_1 (Conv2D)             (None, 3, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "Conv6_2 (Conv2D)             (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "Pool6 (MaxPooling2D)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "Result (Dense)               (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 7,293,890\n",
      "Trainable params: 7,251,074\n",
      "Non-trainable params: 42,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for layer in VGG16().layers[0:4]:\n",
    "#     layer.trainable=False\n",
    "\n",
    "for layer in model_2.layers[0:3]:\n",
    "    layer.trainable=False\n",
    "    print(layer)\n",
    "    \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-82f9085da4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"baseline.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model_2.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(\"baseline.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "batch_size_train = 16\n",
    "steps_train=(len(df_train)/batch_size_train)\n",
    "# batch_size_val= 16\n",
    "# steps_val=int(len(df_val)/batch_size_val)\n",
    "\n",
    "# Fit model with data generator\n",
    "# hist = model_2.fit_generator(steps_per_epoch=steps_train,\n",
    "#                    generator=dp.data_generator(df_train,batch_size_train,seq,(224,224),'all_xrays/train/'),\n",
    "#                    validation_data=(val_data,val_labels),\n",
    "#                    epochs=30,callbacks=[checkpoint,early],\n",
    "#                    class_weight={0:1,1:1.1})\n",
    "\n",
    "# Fit model with weighted classes\n",
    "hist = model_2.fit(x=train_data,y=train_labels,\n",
    "                   validation_data=(val_data,val_labels),\n",
    "                   epochs=6,callbacks=[checkpoint,early], \n",
    "                   class_weight={0:2.7,1:1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.save('Model_4_weighted_Swish.h5')\n",
    "# model_2.save('Model_6_SepConv_Swish.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=2,sharex='col',)\n",
    "\n",
    "ax1.plot(hist.history[\"accuracy\"])\n",
    "ax1.plot(hist.history['val_accuracy'])\n",
    "ax2.plot(hist.history['loss'])\n",
    "ax2.plot(hist.history['val_loss'])\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax1.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
    "ax2.legend([\"loss\",\"Validation Loss\"])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylabel('Loss')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"Model_4_weighted_Swish.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples:  (1175, 224, 224, 3)\n",
      "Total number of labels: (1175, 2)\n"
     ]
    }
   ],
   "source": [
    "imagetype='.jpeg'\n",
    "directory='all_xrays/test/'\n",
    "subfolders=['normal','virus','bacteria']\n",
    "class_labels=[0,1,1]\n",
    "\n",
    "test_data,test_labels=dp.image_data_and_labels(imagetype, directory, subfolders, class_labels)\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f445c75d400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_predict = Sequential()\n",
    "\n",
    "model_predict.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[0])\n",
    "model_predict.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[1])\n",
    "model_predict.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[2])\n",
    "model_predict.add(VGG16(include_top=False, input_shape=(224,224,3)).layers[3])\n",
    "\n",
    "model_predict.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv1_1'))\n",
    "model_predict.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv1_2'))\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool1'))\n",
    "\n",
    "model_predict.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv2_1'))\n",
    "model_predict.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv2_2'))\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool2'))\n",
    "\n",
    "model_predict.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv3_1'))\n",
    "model_predict.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv3_2'))\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool3'))\n",
    "\n",
    "model_predict.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv4_1'))\n",
    "model_predict.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv4_2'))\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool4'))\n",
    "\n",
    "model_predict.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv5_1'))\n",
    "model_predict.add(BatchNormalization())\n",
    "model_predict.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv5_2'))\n",
    "model_predict.add(BatchNormalization())\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool5'))\n",
    "\n",
    "model_predict.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv6_1'))\n",
    "model_predict.add(BatchNormalization())\n",
    "model_predict.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", name='Conv6_2'))\n",
    "model_predict.add(BatchNormalization())\n",
    "model_predict.add(MaxPool2D(pool_size=(2,2),strides=(2,2), name='Pool6'))\n",
    "\n",
    "model_predict.add(Flatten(name=\"Flatten\"))\n",
    "model_predict.add(Dense(units=1024,activation=\"relu\", name='Dense1'))\n",
    "model_predict.add(Dense(units=512,activation=\"relu\", name='Dense2'))\n",
    "model_predict.add(Dense(units=2, activation=\"softmax\", name='Result'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "checkpoint = ModelCheckpoint(\"baseline.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "model_predict.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model_predict.fit(x=train_data,y=train_labels,epochs=0,callbacks=[checkpoint,early],class_weight={0:2.7,1:1})\n",
    "\n",
    "\n",
    "# model_predict=load_model(\"Models/2 Class/Best model/Model_4_2class_datagen_OneOf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 19 layers into a model with 21 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-21fcb74682c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Models/2 Class/Weighted/Model_1_2class_weighted.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1230\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 19 layers into a model with 21 layers."
     ]
    }
   ],
   "source": [
    "model_predict.load_weights('Models/2 Class/Weighted/Model_1_2class_weighted.h5')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = model_predict.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = cm[1][1]/(cm[1][0]+cm[1][1])\n",
    "fpr = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "\n",
    "tpr,fpr,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b1=np.zeros(100)\n",
    "# count=0    \n",
    "# while count<100:\n",
    "#     b1[count] = 10\n",
    "    \n",
    "#     if count%2==0:\n",
    "#         aug_img1 = 20\n",
    "#         aug_img2 = 30\n",
    "#         b1[count+1] = aug_img1\n",
    "#         b1[count+2] = aug_img2\n",
    "\n",
    "#         count +=3\n",
    "#     else:\n",
    "#         count+=1\n",
    "    \n",
    "\n",
    "#     print(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
